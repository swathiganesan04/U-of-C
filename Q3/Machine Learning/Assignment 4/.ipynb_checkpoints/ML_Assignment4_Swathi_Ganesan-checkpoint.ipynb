{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9958d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f3cb1",
   "metadata": {},
   "source": [
    "### 1 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5071bc",
   "metadata": {},
   "source": [
    "##### a) Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d13a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv ('train_data.csv')\n",
    "test = pd.read_csv ('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcb940f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 148)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5aa19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 148)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc5f8e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_G</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.025720</td>\n",
       "      <td>562.504931</td>\n",
       "      <td>1.237574</td>\n",
       "      <td>165.612939</td>\n",
       "      <td>2.187081</td>\n",
       "      <td>2.277318</td>\n",
       "      <td>166.290355</td>\n",
       "      <td>162.291953</td>\n",
       "      <td>168.256667</td>\n",
       "      <td>10.725227</td>\n",
       "      <td>...</td>\n",
       "      <td>24.601144</td>\n",
       "      <td>2.931657</td>\n",
       "      <td>0.817712</td>\n",
       "      <td>0.597732</td>\n",
       "      <td>8.048698</td>\n",
       "      <td>1.455838</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>1398.706114</td>\n",
       "      <td>1101.998185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.619254</td>\n",
       "      <td>698.655240</td>\n",
       "      <td>0.561988</td>\n",
       "      <td>63.230806</td>\n",
       "      <td>0.874054</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>59.217648</td>\n",
       "      <td>73.455101</td>\n",
       "      <td>69.702475</td>\n",
       "      <td>4.968761</td>\n",
       "      <td>...</td>\n",
       "      <td>12.203441</td>\n",
       "      <td>4.942887</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.197505</td>\n",
       "      <td>0.787912</td>\n",
       "      <td>0.451781</td>\n",
       "      <td>0.251287</td>\n",
       "      <td>0.133834</td>\n",
       "      <td>1097.323462</td>\n",
       "      <td>533.927869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>22.910000</td>\n",
       "      <td>26.520000</td>\n",
       "      <td>31.110000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>211.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.580000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>127.485000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.715000</td>\n",
       "      <td>146.460000</td>\n",
       "      <td>97.585000</td>\n",
       "      <td>111.715000</td>\n",
       "      <td>6.985000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.485000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>726.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.950000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>170.650000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>189.630000</td>\n",
       "      <td>158.280000</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>9.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.380000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>8.020000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>1011.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.380000</td>\n",
       "      <td>681.500000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>224.825000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>206.780000</td>\n",
       "      <td>237.375000</td>\n",
       "      <td>238.480000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.825000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1335.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.530000</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>245.870000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>5.410000</td>\n",
       "      <td>239.370000</td>\n",
       "      <td>253.610000</td>\n",
       "      <td>253.630000</td>\n",
       "      <td>30.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.340000</td>\n",
       "      <td>64.700000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>8896.000000</td>\n",
       "      <td>3619.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BrdIndx         Area       Round      Bright     Compact  \\\n",
       "count  507.000000   507.000000  507.000000  507.000000  507.000000   \n",
       "mean     2.025720   562.504931    1.237574  165.612939    2.187081   \n",
       "std      0.619254   698.655240    0.561988   63.230806    0.874054   \n",
       "min      1.000000    22.000000    0.000000   26.850000    1.000000   \n",
       "25%      1.580000   159.000000    0.840000  127.485000    1.650000   \n",
       "50%      1.950000   323.000000    1.210000  170.650000    2.000000   \n",
       "75%      2.380000   681.500000    1.565000  224.825000    2.490000   \n",
       "max      4.530000  5767.000000    3.520000  245.870000    8.070000   \n",
       "\n",
       "          ShpIndx      Mean_G      Mean_R    Mean_NIR        SD_G  ...  \\\n",
       "count  507.000000  507.000000  507.000000  507.000000  507.000000  ...   \n",
       "mean     2.277318  166.290355  162.291953  168.256667   10.725227  ...   \n",
       "std      0.718441   59.217648   73.455101   69.702475    4.968761  ...   \n",
       "min      1.040000   22.910000   26.520000   31.110000    3.550000  ...   \n",
       "25%      1.715000  146.460000   97.585000  111.715000    6.985000  ...   \n",
       "50%      2.180000  189.630000  158.280000  167.750000    9.290000  ...   \n",
       "75%      2.675000  206.780000  237.375000  238.480000   13.330000  ...   \n",
       "max      5.410000  239.370000  253.610000  253.630000   30.870000  ...   \n",
       "\n",
       "       SD_NIR_140      LW_140   GLCM1_140    Rect_140   GLCM2_140    Dens_140  \\\n",
       "count  507.000000  507.000000  507.000000  507.000000  507.000000  507.000000   \n",
       "mean    24.601144    2.931657    0.817712    0.597732    8.048698    1.455838   \n",
       "std     12.203441    4.942887    0.106007    0.197505    0.787912    0.451781   \n",
       "min      2.650000    1.000000    0.200000    0.100000    5.690000    0.240000   \n",
       "25%     14.485000    1.375000    0.770000    0.455000    7.370000    1.160000   \n",
       "50%     22.380000    1.920000    0.840000    0.610000    8.020000    1.440000   \n",
       "75%     33.825000    2.800000    0.890000    0.760000    8.750000    1.775000   \n",
       "max     61.340000   64.700000    0.970000    1.000000    9.570000    2.410000   \n",
       "\n",
       "        Assym_140    NDVI_140  BordLngth_140    GLCM3_140  \n",
       "count  507.000000  507.000000     507.000000   507.000000  \n",
       "mean     0.653905    0.027436    1398.706114  1101.998185  \n",
       "std      0.251287    0.133834    1097.323462   533.927869  \n",
       "min      0.030000   -0.360000      34.000000   211.270000  \n",
       "25%      0.470000   -0.080000     601.000000   726.745000  \n",
       "50%      0.710000   -0.020000    1148.000000  1011.230000  \n",
       "75%      0.860000    0.145000    1874.000000  1335.640000  \n",
       "max      1.000000    0.370000    8896.000000  3619.280000  \n",
       "\n",
       "[8 rows x 147 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1065a0",
   "metadata": {},
   "source": [
    "##### b) Remove any rows that have missing data across both sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d686c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2993da48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 148)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e580bbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 148)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44613e",
   "metadata": {},
   "source": [
    "##### c) The target variable (dependent variable) is called \"class\", make sure to separate this out into a \"y_train\" and \"y_test\" and remove from your \"X_train\" and \"X_test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708c51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class'].to_numpy()\n",
    "\n",
    "\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f5cca",
   "metadata": {},
   "source": [
    "##### d) Scale all features / predictors (NOT THE TARGET VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82e0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# creating a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fitting the scaler to the training data and transform the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# transforming the test data using the scaling parameters learned from the training data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99515449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14075473, -0.61823212, -0.76157526, ..., -0.95313273,\n",
       "         0.10334763,  0.34780924],\n",
       "       [-0.70431561,  0.43196247, -0.53002518, ..., -1.25230517,\n",
       "        -1.09711859,  2.92039508],\n",
       "       [-0.99527502, -0.21993185, -0.42315592, ...,  0.5427295 ,\n",
       "        -0.1830858 , -0.71544325],\n",
       "       ...,\n",
       "       [ 0.68582378,  0.13825184,  0.25368276, ..., -0.87833962,\n",
       "         1.09218151,  0.26440108],\n",
       "       [-0.20321885, -0.67840698, -0.40534437, ..., -1.10271895,\n",
       "        -0.61364815,  0.6910969 ],\n",
       "       [ 0.73431702, -0.58384648,  0.78802909, ..., -1.02792584,\n",
       "        -1.00589775,  1.66713547]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd50e5",
   "metadata": {},
   "source": [
    "### 2 Random Forest Classifier - Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8e40f",
   "metadata": {},
   "source": [
    "##### a) Use the RandomForestClassifier in sklearn. Fit your model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0722c9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest classifier on training data\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3b7b4",
   "metadata": {},
   "source": [
    "##### b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c38299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred_rfc = rfc.predict(X_test_scaled)\n",
    "y_pred_proba_rfc = rfc.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950032dc",
   "metadata": {},
   "source": [
    "##### c) Calculate the confusion matrix and classification report for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06315c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14  0  0  0  0  0  0  0  0]\n",
      " [ 1 22  0  2  0  0  0  0  0]\n",
      " [ 1  1 13  0  0  0  0  0  0]\n",
      " [ 0  5  0 18  0  0  0  0  0]\n",
      " [ 0  0  0  0 25  0  0  0  4]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 3  0  0  0  0  0 13  0  0]\n",
      " [ 0  1  0  5  3  0  0  5  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.70      1.00      0.82        14\n",
      "   building        0.76      0.88      0.81        25\n",
      "        car        0.93      0.87      0.90        15\n",
      "   concrete        0.69      0.78      0.73        23\n",
      "      grass        0.86      0.86      0.86        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        1.00      0.81      0.90        16\n",
      "       soil        1.00      0.36      0.53        14\n",
      "       tree        0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.82       168\n",
      "   macro avg       0.86      0.81      0.81       168\n",
      "weighted avg       0.85      0.82      0.82       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix and classification report\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_rfc))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11690d4",
   "metadata": {},
   "source": [
    "##### d)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc89aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0]\n",
      " [ 0  0  0  0 83  0  0  0  0]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0  0 89]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        1.00      1.00      1.00        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      1.00      1.00        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       1.00      1.00      1.00       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for train data and build confusion matrix and classification report\n",
    "y_pred_train_rfc = rfc.predict(X_train_scaled)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_train, y_pred_train_rfc))\n",
    "print(\"Classification Report: \\n\", classification_report(y_train, y_pred_train_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed3c16",
   "metadata": {},
   "source": [
    "Based on the classification reports, there are signs of overfitting in the model. The train classification report shows perfect precision, recall, and F1-score for all classes, indicating that the model has achieved 100% accuracy on the training data. However, the test classification report shows lower accuracy for some classes, with precision, recall, and F1-scores ranging from 0.69 to 1.00, indicating that the model is not performing as well on unseen data.\n",
    "\n",
    "Moreover, the weighted average F1-score of the test set is 0.82, while the weighted average F1-score of the training set is 1.00. This difference in performance between the training and test sets suggests that the model may have overfit to the training data and is not generalizing well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d6e2d",
   "metadata": {},
   "source": [
    "##### e) Identify the top 5 features. Feel free to print a list OR to make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa04b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 important features of Random Forest Classifier:  ['NDVI' 'Mean_NIR' 'Mean_R_40' 'NDVI_60' 'Mean_NIR_40']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identify top 5 features\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:5]\n",
    "print(\"Top 5 important features of Random Forest Classifier: \", X_train.columns[indices].values)\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances - Random Forest Classifier\")\n",
    "plt.bar(range(5), importances[indices])\n",
    "plt.xticks(range(5), X_train.columns[indices], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12721d0b",
   "metadata": {},
   "source": [
    "### 3 LinearSVM Classifier - Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b58a8",
   "metadata": {},
   "source": [
    "##### a) Use the LinearSVC in sklearn. Fit your model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acd15cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit LinearSVC classifier on train data\n",
    "linear_svc = LinearSVC(random_state=42, max_iter=10000)\n",
    "linear_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b32f7",
   "metadata": {},
   "source": [
    "##### b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e81e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred_linsvc = linear_svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2b6f2",
   "metadata": {},
   "source": [
    "##### c) Calculate the confusion matrix and classification report for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f5dd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  1  1  1  0  0  0  0]\n",
      " [ 0  2 12  0  0  0  0  0  1]\n",
      " [ 1  6  0 15  0  0  0  0  1]\n",
      " [ 0  0  0  1 26  0  0  0  2]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  4  0  1  3  0  0  6  0]\n",
      " [ 0  0  0  1  7  0  0  0  9]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.76      0.93      0.84        14\n",
      "   building        0.65      0.88      0.75        25\n",
      "        car        0.86      0.80      0.83        15\n",
      "   concrete        0.79      0.65      0.71        23\n",
      "      grass        0.70      0.90      0.79        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        0.93      0.88      0.90        16\n",
      "       soil        1.00      0.43      0.60        14\n",
      "       tree        0.69      0.53      0.60        17\n",
      "\n",
      "    accuracy                           0.77       168\n",
      "   macro avg       0.82      0.76      0.77       168\n",
      "weighted avg       0.80      0.77      0.77       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix and classification report\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_linsvc))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred_linsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4e631",
   "metadata": {},
   "source": [
    "##### d)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "274c37bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0]\n",
      " [ 0  1  0  0 80  0  0  0  2]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0  0 89]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.99      1.00      0.99        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      0.96      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        0.98      1.00      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for train data and build confusion matrix and classification report\n",
    "y_pred_train_linsvc = linear_svc.predict(X_train_scaled)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_train, y_pred_train_linsvc))\n",
    "print(\"Classification Report: \\n\", classification_report(y_train, y_pred_train_linsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0798167",
   "metadata": {},
   "source": [
    "Based on the given classification reports, there seems to be signs of overfitting. The train classification report shows perfect precision, recall and f1-score values (all 1.00) for all classes, which indicates that the model has memorized the training data and performs very well on it. On the other hand, the test classification report shows lower precision, recall, and f1-score values for some classes and an overall lower accuracy, which suggests that the model is not generalizing well to unseen data.\n",
    "\n",
    "The lower performance of the model on the test data compared to the train data suggests that the model is overfitting to the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e0256",
   "metadata": {},
   "source": [
    "### 4 Support Vector Machine Classifier + Linear Kernel + Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e757b0",
   "metadata": {},
   "source": [
    "##### a) Use SVC from sklearn with kernel = \"linear\". Run the GridSearchCV using the following (SVMs run much faster than RandomForest):\n",
    "\n",
    "    C: 0.01 - 10 in increments of 0.2 (consider using the np.arange() method from numpy to build out a sequence of values)\n",
    "    Use 5 cross-fold and the default scoring. Please set verbose = 0 to reduce the printing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac7777b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear', random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4.610e+00,\n",
       "       4.810e+00, 5.010e+00, 5.210e+00, 5.410e+00, 5.610e+00, 5.810e+00,\n",
       "       6.010e+00, 6.210e+00, 6.410e+00, 6.610e+00, 6.810e+00, 7.010e+00,\n",
       "       7.210e+00, 7.410e+00, 7.610e+00, 7.810e+00, 8.010e+00, 8.210e+00,\n",
       "       8.410e+00, 8.610e+00, 8.810e+00, 9.010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01])})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of SVM with a linear kernel\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# specify the parameters to be tuned\n",
    "parameters = {'C': np.arange(0.01, 10.2, 0.2)}\n",
    "\n",
    "# create a GridSearchCV object with 5-fold cross-validation\n",
    "grid_search_svc = GridSearchCV(svc, parameters, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b991852",
   "metadata": {},
   "source": [
    "##### b) Identify the best performing model:\n",
    "\n",
    ".best_params_() : This method outputs to best performing parameters\n",
    ".best_estimator_() : This method outputs the best performing model, and can be used for predicting on the X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc0b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n",
      "SVC(C=0.01, kernel='linear', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters\n",
    "print(grid_search_svc.best_params_)\n",
    "\n",
    "# print the best estimator\n",
    "best_model_svc = grid_search_svc.best_estimator_\n",
    "print(best_model_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e0c98",
   "metadata": {},
   "source": [
    "##### c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5bee6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data\n",
    "y_pred_svc = best_model_svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8796d",
   "metadata": {},
   "source": [
    "##### d) Calculate the confusion matrix and classification report for test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2367f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  1 25  0  0  0  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  5  2  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.71      0.88      0.79        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.65      0.74      0.69        23\n",
      "      grass        0.83      0.86      0.85        29\n",
      "       pool        1.00      0.93      0.97        15\n",
      "     shadow        0.88      0.94      0.91        16\n",
      "       soil        0.80      0.29      0.42        14\n",
      "       tree        0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.82       168\n",
      "   macro avg       0.85      0.81      0.82       168\n",
      "weighted avg       0.83      0.82      0.81       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix and classification report\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_svc))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353163a",
   "metadata": {},
   "source": [
    "##### e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1818ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[40  0  0  0  0  0  5  0  0]\n",
      " [ 2 87  0  7  0  0  1  0  0]\n",
      " [ 0  1 19  1  0  0  0  0  0]\n",
      " [ 0  9  0 83  1  0  0  0  0]\n",
      " [ 0  1  0  0 70  0  0  0 12]\n",
      " [ 0  1  0  0  1 12  0  0  0]\n",
      " [ 1  0  0  0  0  0 43  0  1]\n",
      " [ 0  3  0  4  2  0  0 11  0]\n",
      " [ 0  0  0  0  3  0  1  0 85]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.89      0.91        45\n",
      "   building        0.85      0.90      0.87        97\n",
      "        car        1.00      0.90      0.95        21\n",
      "   concrete        0.87      0.89      0.88        93\n",
      "      grass        0.91      0.84      0.88        83\n",
      "       pool        1.00      0.86      0.92        14\n",
      "     shadow        0.86      0.96      0.91        45\n",
      "       soil        1.00      0.55      0.71        20\n",
      "       tree        0.87      0.96      0.91        89\n",
      "\n",
      "    accuracy                           0.89       507\n",
      "   macro avg       0.92      0.86      0.88       507\n",
      "weighted avg       0.89      0.89      0.89       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for train data and build confusion matrix and classification report\n",
    "y_pred_train_svc = best_model_svc.predict(X_train_scaled)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_train, y_pred_train_svc))\n",
    "print(\"Classification Report: \\n\", classification_report(y_train, y_pred_train_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39970da4",
   "metadata": {},
   "source": [
    "Based on the classification reports, there seems to be some signs of overfitting in the model. The accuracy on the training set is significantly higher than the accuracy on the test set, which indicates that the model is fitting too closely to the training data and not generalizing well to new data.\n",
    "\n",
    "For example, the precision, recall, and f1-score on the training set are all above 0.87, while on the test set, they range from 0.42 to 0.97. This suggests that the model is performing very well on the training data, but is not as accurate or consistent when tested on new data.\n",
    "\n",
    "Furthermore, the precision and recall values for the 'soil' class is noticeably lower on the test set than on the training set. This could indicate that the model is overfitting on the training data for these classes, which may be due to insufficient training examples or class imbalance.\n",
    "\n",
    "In summary, the lower accuracy and lower precision/recall/f1-score on the test set compared to the training set suggest that there may be signs of overfitting in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86176d",
   "metadata": {},
   "source": [
    "### 5 Support Vector Machine Classifier + Polynomial Kernel + Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a738c6",
   "metadata": {},
   "source": [
    "##### a) Use SVC from sklearn with kernel = \"poly\". Run the GridSearchCV using the following:\n",
    "\n",
    "    C: 0.01 - 10 in increments of 0.2\n",
    "    degree: 2, 3, 4, 5, 6\n",
    "    Use 5 cross-fold and the default scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a896791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='poly', random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4.610e+00,\n",
       "       4.810e+00, 5.010e+00, 5.210e+00, 5.410e+00, 5.610e+00, 5.810e+00,\n",
       "       6.010e+00, 6.210e+00, 6.410e+00, 6.610e+00, 6.810e+00, 7.010e+00,\n",
       "       7.210e+00, 7.410e+00, 7.610e+00, 7.810e+00, 8.010e+00, 8.210e+00,\n",
       "       8.410e+00, 8.610e+00, 8.810e+00, 9.010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01]),\n",
       "                         'degree': [2, 3, 4, 5, 6]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of SVM with a polynomial kernel\n",
    "svc_poly = SVC(kernel='poly', random_state=42)\n",
    "\n",
    "# specify the parameters to be tuned\n",
    "parameters = {'C': np.arange(0.01, 10.2, 0.2), 'degree': [2, 3, 4, 5, 6]}\n",
    "\n",
    "# create a GridSearchCV object with 5-fold cross-validation\n",
    "grid_search_poly = GridSearchCV(svc_poly, parameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search_poly.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a183c7b",
   "metadata": {},
   "source": [
    "##### b) Identify the best performing model:\n",
    "\n",
    ".best_params_() : This method outputs to best performing parameters\n",
    ".best_estimator_() : This method outputs the best performing model, and can be used for predicting on the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2544b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.81, 'degree': 3}\n",
      "SVC(C=3.81, kernel='poly', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters\n",
    "print(grid_search_poly.best_params_)\n",
    "\n",
    "# print the best estimator\n",
    "best_model_svc_poly = grid_search_poly.best_estimator_\n",
    "print(best_model_svc_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82eb422",
   "metadata": {},
   "source": [
    "##### c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d7eb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data\n",
    "y_pred_svc_poly = best_model_svc_poly.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5d43b",
   "metadata": {},
   "source": [
    "##### d) Calculate the confusion matrix and classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45fcfa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  2 11  0  0  1  0  1  0]\n",
      " [ 0  5  0 17  1  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  1  2]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 14  0  1]\n",
      " [ 0  2  0  5  7  0  0  0  0]\n",
      " [ 0  0  0  1  3  0  0  0 13]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.71      0.88      0.79        25\n",
      "        car        1.00      0.73      0.85        15\n",
      "   concrete        0.68      0.74      0.71        23\n",
      "      grass        0.68      0.90      0.78        29\n",
      "       pool        0.93      0.93      0.93        15\n",
      "     shadow        0.88      0.88      0.88        16\n",
      "       soil        0.00      0.00      0.00        14\n",
      "       tree        0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.77       168\n",
      "   macro avg       0.74      0.75      0.74       168\n",
      "weighted avg       0.73      0.77      0.75       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix and classification report\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_svc_poly))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred_svc_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d9667",
   "metadata": {},
   "source": [
    "##### e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17a4e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[44  0  0  0  1  0  0  0  0]\n",
      " [ 0 95  0  1  1  0  0  0  0]\n",
      " [ 0  0 20  0  1  0  0  0  0]\n",
      " [ 0  1  0 91  1  0  0  0  0]\n",
      " [ 0  1  0  0 81  0  0  0  1]\n",
      " [ 0  0  0  0  1 13  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0 11  0  0  9  0]\n",
      " [ 0  0  0  0  5  0  0  0 84]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      0.98      0.99        45\n",
      "   building        0.98      0.98      0.98        97\n",
      "        car        1.00      0.95      0.98        21\n",
      "   concrete        0.99      0.98      0.98        93\n",
      "      grass        0.79      0.98      0.88        83\n",
      "       pool        1.00      0.93      0.96        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.45      0.62        20\n",
      "       tree        0.99      0.94      0.97        89\n",
      "\n",
      "    accuracy                           0.95       507\n",
      "   macro avg       0.97      0.91      0.93       507\n",
      "weighted avg       0.96      0.95      0.95       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for train data and build confusion matrix and classification report\n",
    "y_pred_train_svc_poly = best_model_svc_poly.predict(X_train_scaled)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_train, y_pred_train_svc_poly))\n",
    "print(\"Classification Report: \\n\", classification_report(y_train, y_pred_train_svc_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3891e",
   "metadata": {},
   "source": [
    "Yes, there are signs of overfitting in this case. The training classification report shows very high precision, recall and f1-scores across all categories, with an accuracy of 0.95. However, the test classification report shows lower scores across most categories, with an accuracy of only 0.77. This indicates that the model has not generalized well to unseen data, and has instead memorized the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c496c",
   "metadata": {},
   "source": [
    "### 6 Support Vector Machine Classifier + RBF Kernel + Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec29f7",
   "metadata": {},
   "source": [
    "##### a) Use SVC from sklearn with kernel = \"rbf\". Run the GridSearchCV using the following:\n",
    "\n",
    "    C: 0.01 - 10 in increments of 0.2\n",
    "    gamma: 0.01,  0.1, 1, 10, 100\n",
    "    Use 5 cross-fold and the default scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27cff689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4.610e+00,\n",
       "       4.810e+00, 5.010e+00, 5.210e+00, 5.410e+00, 5.610e+00, 5.810e+00,\n",
       "       6.010e+00, 6.210e+00, 6.410e+00, 6.610e+00, 6.810e+00, 7.010e+00,\n",
       "       7.210e+00, 7.410e+00, 7.610e+00, 7.810e+00, 8.010e+00, 8.210e+00,\n",
       "       8.410e+00, 8.610e+00, 8.810e+00, 9.010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01]),\n",
       "                         'gamma': [0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the parameter grid\n",
    "param_grid = {'C': np.arange(0.01, 10.2, 0.2), 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create an instance of the SVC with RBF kernel\n",
    "svc_rbf = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# create an instance of GridSearchCV\n",
    "grid_search_rbf = GridSearchCV(estimator=svc_rbf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search_rbf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214b868",
   "metadata": {},
   "source": [
    "##### b) Identify the best performing model\n",
    "\n",
    "    .best_params_(): This method outputs to best performing parameters\n",
    "    .best_estimator_(): This method outputs the best performing model, and can be used for predicting on the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f99b92a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.81, 'gamma': 0.01}\n",
      "SVC(C=2.81, gamma=0.01, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# output the best performing parameters\n",
    "print(grid_search_rbf.best_params_)\n",
    "\n",
    "# output the best performing model\n",
    "best_model_svc_rbf = grid_search_rbf.best_estimator_\n",
    "print(best_model_svc_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f493a",
   "metadata": {},
   "source": [
    "##### c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b90dd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data using the best performing model\n",
    "y_pred_svc_rbf = best_model_svc_rbf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b81ba",
   "metadata": {},
   "source": [
    "##### d) Calculate the confusion matrix and classification report for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c6128ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 21  0  3  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  1  0  0 26  0  0  0  2]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  2  0  4  3  0  0  5  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.72      0.84      0.78        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.70      0.83      0.76        23\n",
      "      grass        0.84      0.90      0.87        29\n",
      "       pool        1.00      0.93      0.97        15\n",
      "     shadow        0.88      0.94      0.91        16\n",
      "       soil        1.00      0.36      0.53        14\n",
      "       tree        0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.85       168\n",
      "   macro avg       0.88      0.84      0.84       168\n",
      "weighted avg       0.86      0.85      0.84       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix and classification report\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_svc_rbf))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred_svc_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7941c",
   "metadata": {},
   "source": [
    "##### e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77292cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 96  0  1  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  1  0 92  0  0  0  0  0]\n",
      " [ 0  1  0  0 81  0  0  0  1]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  1  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  1  0  0  0 88]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.97      0.99      0.98        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        0.99      0.99      0.99        93\n",
      "      grass        0.99      0.98      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.95      0.97        20\n",
      "       tree        0.99      0.99      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       0.99      0.99      0.99       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for train data and build confusion matrix and classification report\n",
    "y_pred_train_svc_rbf = best_model_svc_rbf.predict(X_train_scaled)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_train, y_pred_train_svc_rbf))\n",
    "print(\"Classification Report: \\n\", classification_report(y_train, y_pred_train_svc_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e99430",
   "metadata": {},
   "source": [
    "There are signs of overfitting in this scenario. The accuracy of the model on the training data is significantly higher (99%) than the accuracy on the test data (85%). Additionally, the precision, recall, and F1-score for the training data are consistently high for all classes, indicating that the model is likely fitting to the specific features of the training data, rather than generalizing to new, unseen data.\n",
    "\n",
    "Furthermore, the precision, recall, and F1-score for the soil class are relatively low for the test data compared to the other classes, suggesting that the model may not be performing as well on this class, which could be an indication of overfitting.\n",
    "\n",
    "Overall, while the model appears to be performing well on both the training and test data, the significant difference in accuracy and the lower performance on one class suggest overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9caa1c",
   "metadata": {},
   "source": [
    "### 7 Conceptual Questions:\n",
    "\n",
    "<i>a) From the models run in steps 2-6, which performs the best based on the Classification Report? Support your reasoning with evidence around your test data. </i>\n",
    "\n",
    "In our case, the <b>SVM with linear kernel model</b> performed the best with comparable accuracy scores on both the train and test data. SVM with Linear kernel performs well on linearly seperable data and is computationally inexpensive and effective on data where the number of features is high. We can also observe that almost all the models are unable to generalise for the 'soil' class which is afffecting the accuracy scores. Hence, based on the classification report, with a test accuracy of 82% and a train accuracy of 89%, the SVM with Linear kernel model performed the best for our data.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i>b) Compare models run for steps 4-6 where different kernels were used. What is the benefit of using a polynomial or rbf kernel over a linear kernel? What could be a downside of using a polynomial or rbf kernel? </i>\n",
    "\n",
    "The main benefit of using polynomial or radial basis function (RBF) kernels over a linear kernel in SVM is that they allow for more complex decision boundaries, which can lead to better classification performance.\n",
    "\n",
    "In a linear kernel, the decision boundary is a straight line or hyperplane that separates the classes. However, in many cases, the classes may not be linearly separable, meaning that a linear boundary cannot accurately classify all the data points. In such cases, polynomial or RBF kernels can be used to create non-linear decision boundaries that can better separate the classes.\n",
    "\n",
    "The downside of using polynomial or RBF kernels is that they can be computationally expensive, especially when dealing with large datasets. This is because these kernels involve calculating the similarity between each pair of data points, which can be time-consuming. Additionally, if the kernel is poorly chosen or the kernel parameters are not well-tuned, it can lead to overfitting or underfitting, which can result in poor generalization performance on new data.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i>c) Explain the 'C' parameter used in steps 4-6. What does a small C mean versus a large C in sklearn? Why is it important to use the 'C' parameter when fitting a model? </i>\n",
    "\n",
    "The <b>'C' parameter</b> is a hyperparameter used in the SVM algorithm in sklearn. It controls the trade-off between achieving a low training error and a low testing error. In other words, it controls the degree to which the SVM should avoid misclassifying each training example.\n",
    "\n",
    "A small value of C means that the SVM is more tolerant of errors on the training set, which can lead to a smoother decision boundary and may allow for more margin errors. On the other hand, a large value of C means that the SVM will try to classify all training examples correctly, even if it means creating a decision boundary that is more complex and has smaller margins.\n",
    "\n",
    "It is important to use the 'C' parameter when fitting a model because it allows the user to balance the bias-variance trade-off. A low value of C may lead to a model that is underfitting the data, as it is too tolerant of errors on the training set. A high value of C may lead to a model that is overfitting the data, as it is trying to fit the training set too closely and is not generalizing well to new, unseen data. Therefore, selecting an appropriate value of C is crucial for achieving good performance with SVM models.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i>d) Scaling our input data does not matter much for Random Forest, but it is a critical step for Support Vector Machines. Explain why this is such a critical step. Also, provide an example of a feature from this data set that could cause issues with our SVMs if not scaled.</i>\n",
    "\n",
    "Support Vector Machines (SVMs) are sensitive to the scale of the input features. SVM tries to find the hyperplane that maximizes the margin, which is the distance between the hyperplane and the closest data points. When features have different scales, their contribution to the distance calculation is biased towards the features with larger scales. To avoid this bias, it's important to scale the input features so that they all have a similar scale. This ensures that each feature contributes equally to the distance calculation.\n",
    "\n",
    "On the other hand, Random Forests are based on decision trees, which split the data into smaller subsets based on a single feature at a time. Therefore, the scale of the features does not affect the performance of Random Forests as much as it does for SVMs. In fact, Random Forests are known to be relatively insensitive to the scale of the input features, making scaling less important for this algorithm.\n",
    "\n",
    "On describing the train data set, we can observe that the some features like <b>'Area' and 'Bright'</b> are in the range of (22, 5767) and (26, 245) respectively compared to other features like 'Round' and 'Compact' which are in the range (0, 8). If the data is not scaled, the 'Area' will have a much larger impact on the distance calculation than the other features, simply because of its larger scale.\n",
    "\n",
    "<br>\n",
    "\n",
    "<i>e) Describe conceptually what the purpose of a kernel is for Support Vector Machines.</i>\n",
    "\n",
    "The purpose of a kernel in Support Vector Machines (SVMs) is to transform the input data into a higher-dimensional space, where it may be more easily separable. SVMs are used for classification and regression problems and work by finding the hyperplane that maximizes the margin between two classes. However, in cases where the data is not linearly separable in the original feature space, a kernel function can be used to map the data into a higher-dimensional space, where it may become linearly separable.\n",
    "\n",
    "Kernels provide a way of computing the dot product between two vectors in the transformed space without explicitly calculating the transformation. This is computationally efficient and is known as the \"kernel trick\". SVMs can use various types of kernel functions such as linear, polynomial, radial basis function (RBF), and sigmoid. Each kernel function has its own characteristics, which can be used to tune the model's performance for a particular dataset.\n",
    "\n",
    "In summary, the kernel function plays a crucial role in SVMs by mapping the input data into a higher-dimensional space where it may be more easily separable, allowing SVMs to find the optimal hyperplane that maximizes the margin between two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
